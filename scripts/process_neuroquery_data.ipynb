{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process NeuroQuery Data into Yale Brain Atlas Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qWP20cEKC6k2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "from neuroquery import fetch_neuroquery_model, NeuroQueryModel\n",
    "from nilearn.plotting import view_img\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# Download NeuroQuery encoder\n",
    "encoder = NeuroQueryModel.from_data_dir(fetch_neuroquery_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to convert between voxel and world coordinate space; requires extracting affine matrix\n",
    "def voxel_to_world_coordinates(voxel_coords, affine):\n",
    "    \"\"\"\n",
    "    Convert voxel coordinates to world coordinates.\n",
    "    :param voxel_coords: numpy array of voxel coordinates (3,)\n",
    "    :param affine: numpy array representing the affine transformation (4, 4)\n",
    "    :return: numpy array of world coordinates (3,)\n",
    "    \"\"\"\n",
    "    voxel_coords_homogeneous = np.append(voxel_coords, 1)  # Convert to homogeneous coordinates\n",
    "    world_coords_homogeneous = affine @ voxel_coords_homogeneous  # Matrix multiplication\n",
    "    return world_coords_homogeneous[:3]  # Return only the x, y, z world coordinates\n",
    "\n",
    "def world_to_voxel_coordinates(world_coords, affine):\n",
    "    \"\"\"\n",
    "    Convert world coordinates to voxel indices.\n",
    "    \n",
    "    Parameters:\n",
    "    - world_coords: numpy array of shape (3,) for world coordinates (x, y, z).\n",
    "    - affine: numpy array of shape (4, 4), the affine transformation matrix.\n",
    "    \n",
    "    Returns:\n",
    "    - voxel_coords: numpy array of shape (3,) for voxel indices.\n",
    "    \"\"\"\n",
    "    # Invert the affine matrix\n",
    "    affine_inv = np.linalg.inv(affine)\n",
    "    # Convert world coordinates to homogeneous coordinates\n",
    "    world_homogeneous = np.append(world_coords, 1)\n",
    "    # Apply the inverted affine matrix\n",
    "    voxel_homogeneous = np.dot(affine_inv, world_homogeneous)\n",
    "    # Drop the homogeneous coordinate\n",
    "    voxel_coords = voxel_homogeneous[:3]\n",
    "    return voxel_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get brain maps for each of the 334 functional terms\n",
    "metaanalysis_functional_terms_df = pd.read_csv(\"../data/metaanalysis/metaanalysis_functional_terms.csv\")\n",
    "functional_terms = metaanalysis_functional_terms_df[\"new_neuroquery_functional_term\"].unique()\n",
    "\n",
    "brain_map_affine = encoder(\"math\")[\"brain_map\"].affine # standard across all terms\n",
    "\n",
    "brain_map_allterms_data = np.empty((46, 55, 46, 334)) # dimensions x,y,z,functional terms\n",
    "for i in range(len(functional_terms)):\n",
    "    brain_map_i = encoder(functional_terms[i])[\"brain_map\"]\n",
    "    brain_map_i_data = brain_map_i.get_fdata()\n",
    "    brain_map_allterms_data[:,:,:,i] = brain_map_i_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Yale Brain Atlas positions (whole brain) and parcel names\n",
    "atlas_whole_positions = pd.read_csv(\"../data/atlas/atlas_whole_positions.csv\")\n",
    "parcel_names = atlas_whole_positions[\"parcel\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, round the 'x', 'y', and 'z' columns to the nearest integer\n",
    "# Important for indexing with NeuroQuery maps\n",
    "atlas_whole_positions_rounded = atlas_whole_positions\n",
    "atlas_whole_positions_rounded['x'] = atlas_whole_positions_rounded['x'].round(0)\n",
    "atlas_whole_positions_rounded['y'] = atlas_whole_positions_rounded['y'].round(0)\n",
    "atlas_whole_positions_rounded['z'] = atlas_whole_positions_rounded['z'].round(0)\n",
    "\n",
    "# Convert to voxel coordinates for indexing purposes\n",
    "for index, row in atlas_whole_positions_rounded.iterrows():\n",
    "    voxel_coords = world_to_voxel_coordinates(np.array([row['x'], row['y'], row['z']]), brain_map_affine)\n",
    "    atlas_whole_positions_rounded.loc[index, ['x_voxel', 'y_voxel', 'z_voxel']] = voxel_coords\n",
    "\n",
    "# Now, round the 'x', 'y', and 'z' columns to the nearest integer\n",
    "atlas_whole_positions_rounded['x_voxel'] = atlas_whole_positions_rounded['x_voxel'].round(0).astype(int)\n",
    "atlas_whole_positions_rounded['y_voxel'] = atlas_whole_positions_rounded['y_voxel'].round(0).astype(int)\n",
    "atlas_whole_positions_rounded['z_voxel'] = atlas_whole_positions_rounded['z_voxel'].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each parcel, get the activations at the constituent x,y,z positions for each term, then take average for each term\n",
    "# Resulting dataframe is average activation value for 334 functional terms across 696 parcels\n",
    "neuroquery_functional_activation_database = np.empty((696, 334))\n",
    "for i in range(len(parcel_names)):\n",
    "    parcel_i = parcel_names[i]\n",
    "    atlas_whole_positions_rounded_parcel_i = atlas_whole_positions_rounded[atlas_whole_positions_rounded['parcel'] == parcel_names[i]]\n",
    "    for j in range(len(functional_terms)):\n",
    "        brain_map_j_data = brain_map_allterms_data[:,:,:,j]\n",
    "        activation_values_parcel_i_term_j = brain_map_j_data[atlas_whole_positions_rounded_parcel_i[\"x_voxel\"].values,\n",
    "                                                             atlas_whole_positions_rounded_parcel_i[\"y_voxel\"].values,\n",
    "                                                             atlas_whole_positions_rounded_parcel_i[\"z_voxel\"].values]\n",
    "        neuroquery_functional_activation_database[i,j] = np.mean(activation_values_parcel_i_term_j)\n",
    "\n",
    "neuroquery_functional_activation_database = pd.DataFrame(neuroquery_functional_activation_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to functional terms\n",
    "column_name_map = dict(zip(list(neuroquery_functional_activation_database.columns.values), functional_terms))\n",
    "neuroquery_functional_activation_database = neuroquery_functional_activation_database.rename(columns = column_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all negative activations to 0\n",
    "neuroquery_functional_activation_database = neuroquery_functional_activation_database.clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroquery_functional_activation_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "neuroquery_functional_activation_database.to_csv(\"../data/neurosynth/neuroquery_functional_activation_database.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
